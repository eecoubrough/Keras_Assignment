{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eecoubrough/Keras_Assignment/blob/main/Part_1_binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKbgFz4AhYvK"
      },
      "source": [
        "# Deep Learning Medical Image Analysis Example\n",
        "A simple convolutional neural network model trained using a simple pathology image dataset.\n",
        "\n",
        "To use GPU acceleration make sure to change your runtime type in Google Colab to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LICWjsiH5Ysh"
      },
      "source": [
        "## Python Imports\n",
        "This section will load the necessary python packages to the instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r14DjPX5XAT"
      },
      "source": [
        "# Built-in Imports\n",
        "import random"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9akxJOL576W"
      },
      "source": [
        "# Library Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import tabulate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPushucynmye"
      },
      "source": [
        "# Keras Imports\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import get_file, to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfG7LUYZz6I2"
      },
      "source": [
        "## Dataset Downloader\n",
        "This section will download the PneumoniaMNIST dataset as a NumPy array object to the Google Colab instance. Note that the dataset does need to be redownloaded every time an instance is created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFsupyTxnHgN"
      },
      "source": [
        "# The dataset selected is PneumoniaMNIST\n",
        "# If desired, a different MedMNIST dataset could be used simply by specifying the desired dataset name.\n",
        "DATA_NAME = \"PneumoniaMNIST\""
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrpiQg5VkbsL",
        "outputId": "78bb5689-899f-424f-b6c1-c50d2dfa3e14"
      },
      "source": [
        "# Retrieves the dataset from GitHub\n",
        "!wget https://raw.githubusercontent.com/MedMNIST/MedMNIST/main/medmnist/info.py\n",
        "from info import INFO\n",
        "data = INFO[DATA_NAME.lower()]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-01 14:56:49--  https://raw.githubusercontent.com/MedMNIST/MedMNIST/main/medmnist/info.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27766 (27K) [text/plain]\n",
            "Saving to: ‘info.py.1’\n",
            "\n",
            "\rinfo.py.1             0%[                    ]       0  --.-KB/s               \rinfo.py.1           100%[===================>]  27.12K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-01 14:56:49 (14.0 MB/s) - ‘info.py.1’ saved [27766/27766]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbCWsdDP0ECH"
      },
      "source": [
        "# Downloads the dataset file hosted on Zenodo.\n",
        "file_path = get_file(fname=\"dataset.npz\",\n",
        "                     origin=data[\"url\"],\n",
        "                     md5_hash=data[\"MD5\"])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the downloaded NumPy object, saving it to the variable 'dataset'.\n",
        "dataset = np.load(file_path)\n",
        "\n",
        "# Gets the training images and labels from the NumPy object.\n",
        "train_x = dataset[\"train_images\"]\n",
        "# Adds an extra new dimension to the training images array to make it compatible with CNNs.\n",
        "    # This is necessary because the dataset is greyscale images are represented by a 2D array, but CNNs require a 3D input tensor.\n",
        "    # By adding a new dimension with size 1, it explicitly specifies that there is just one channel (for grayscale) in addition to height and width.\n",
        "train_x = np.expand_dims(train_x, axis=-1)\n",
        "train_y = dataset[\"train_labels\"]\n",
        "\n",
        "# Gets the validation images and labels from the NumPy object.\n",
        "val_x = dataset[\"val_images\"]\n",
        "# Adds an extra new dimension to the training images array to make it compatible with CNNs.\n",
        "val_x = np.expand_dims(val_x, axis=-1)\n",
        "val_y = dataset[\"val_labels\"]\n",
        "\n",
        "# Gets the testing images and labels from the NumPy object.\n",
        "test_x = dataset[\"test_images\"]\n",
        "# Adds an extra new dimension to the training images array to make it compatible with CNNs.\n",
        "test_x = np.expand_dims(test_x, axis=-1)\n",
        "test_y = dataset[\"test_labels\"]"
      ],
      "metadata": {
        "id": "rg3BshBkvuNy"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRN-KCObfI18"
      },
      "source": [
        "## Data Exploration\n",
        "In this section we have a look at our data, their distributions to see if it is ready to be used within our machine learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of one of the images in your dataset to ensure the images are in the expected shape format.\n",
        "print(train_x[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR5PtCQPxNp-",
        "outputId": "37d77e1a-e148-470c-ae98-0b1e3148dc6e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMAxCIw3-JOW",
        "outputId": "d3d6eca8-35bf-41e1-ec20-d937b7e766c5"
      },
      "source": [
        "# Declares a list of labels.\n",
        "labels = list(data[\"label\"].values()) + [\"total\"]\n",
        "\n",
        "# Gets the counts for each label in each of our datasets.\n",
        "_, train_counts = np.unique(train_y, return_counts=True)\n",
        "_, val_counts = np.unique(val_y, return_counts=True)\n",
        "_, test_counts = np.unique(test_y, return_counts=True)\n",
        "\n",
        "# Prints the counts for each label from each dataset (used to check the distributions of data in each of the eight classes to ensure there is no unexpected discepencies).\n",
        "print(pd.DataFrame(list(zip(np.append(train_counts, [sum(train_counts)]),\n",
        "                            np.append(val_counts, [sum(val_counts)]),\n",
        "                            np.append(test_counts, [sum(test_counts)]))),\n",
        "                   index=labels, columns=[\"Train\", \"Val\", \"Test\"]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Train  Val  Test\n",
            "normal      1214  135   234\n",
            "pneumonia   3494  389   390\n",
            "total       4708  524   624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "AQ4Qba5sdt_Q",
        "outputId": "45331180-2998-41a4-8bde-134c05996553"
      },
      "source": [
        "# Displays a random image from training dataset.\n",
        "index = random.randint(0, len(train_x))\n",
        "print(f\"{index}: {labels[train_y[index][0]]}\")\n",
        "plt.imshow(train_x[random.randint(0, len(train_x))])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2883: pneumonia\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ac978f13550>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61PPEn8Dhp_v"
      },
      "source": [
        "## Data Processing\n",
        "In this section we will create a data loader for algorithm that will dynamically load and augment the data when needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKrtg2heh4tF"
      },
      "source": [
        "# Defines the data generator that will be used to augment the images as they are loaded.\n",
        "data_generator = ImageDataGenerator(featurewise_center=True,\n",
        "                                    featurewise_std_normalization=True,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5TzJV-O3nD7"
      },
      "source": [
        "data_generator.fit(np.append(train_x, val_x, 0))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# **Part 1 - Covnet with same architechture and training regime**\n"
      ],
      "metadata": {
        "id": "TPh8GA_wE2dx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptmuEdE1p9MU"
      },
      "source": [
        "## Model Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud-jcR_ZqE0V",
        "outputId": "af721dab-2444-4254-fdfe-f2944cf181a2"
      },
      "source": [
        "# Define the input layer of the model with the size of an image.\n",
        "input = layers.Input(shape=train_x[0].shape)\n",
        "\n",
        "# Defines the first convolutional layer with max pooling.\n",
        "conv_1 = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(input)\n",
        "pool_1 = layers.MaxPool2D(pool_size=(2, 2))(conv_1)\n",
        "\n",
        "# Defines the second convolutional layer with max pooling.\n",
        "conv_2 = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(pool_1)\n",
        "pool_2 = layers.MaxPool2D(pool_size=(2, 2))(conv_2)\n",
        "\n",
        "# Flattens the outputs of the convolutional layers into a one dimensional array.\n",
        "flatten = layers.Flatten()(pool_2)\n",
        "\n",
        "# Defines the output layer of the model a number of output nodes equal to the number of classes.\n",
        "output = layers.Dense(units=1, activation=\"sigmoid\")(flatten)\n",
        "\n",
        "# Initilises the defined model and prints summary of the model.\n",
        "model_1 = Model(inputs=input, outputs=output, name=\"Model_1\")\n",
        "model_1.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 801       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10369 (40.50 KB)\n",
            "Trainable params: 10369 (40.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdMcAtCztO0b"
      },
      "source": [
        "## Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEypwRiMuPCn"
      },
      "source": [
        "# Define the parameters used during training.\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb9WcL7ZtPZE"
      },
      "source": [
        "# Defines the optimiser used to adjust the model weights and compiles the model.\n",
        "optimiser = SGD(learning_rate=LEARNING_RATE)\n",
        "model_1.compile(optimizer=optimiser, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOy4ArHyvIhR",
        "outputId": "116edb8a-905f-4907-aadf-f777e65ee7e7"
      },
      "source": [
        "# Use data generator to pass the training and validation data to the model to train it.\n",
        "history_1 = model_1.fit(data_generator.flow(train_x, train_y, batch_size=BATCH_SIZE),\n",
        "                    steps_per_epoch=len(train_x) / BATCH_SIZE,\n",
        "                    validation_data=data_generator.flow(val_x, val_y, batch_size=BATCH_SIZE),\n",
        "                    validation_steps=len(val_x) / BATCH_SIZE,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 4s 42ms/step - loss: 0.6749 - accuracy: 0.6164 - val_loss: 0.6430 - val_accuracy: 0.7405\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 3s 39ms/step - loss: 0.6209 - accuracy: 0.7411 - val_loss: 0.6085 - val_accuracy: 0.7424\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.5940 - accuracy: 0.7421 - val_loss: 0.5912 - val_accuracy: 0.7424\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.5796 - accuracy: 0.7421 - val_loss: 0.5801 - val_accuracy: 0.7424\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 3s 39ms/step - loss: 0.5702 - accuracy: 0.7421 - val_loss: 0.5723 - val_accuracy: 0.7424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bw_0oKy4UdI"
      },
      "source": [
        "## Plot Learning Curves\n",
        "This is where we visualise the training of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DOxQYV0oDmJ"
      },
      "source": [
        "# Plots the training and validation accuracy over the number of epochs.\n",
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "\n",
        "# Add plot title.\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "# Add plot axes labels.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Add plot legend to distinguish between training and validation accuracy lines.\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training accuracy is moderately low at the beginning, increasing rapidly before flattening out at approximately 3.5 epochs. This indicates that the addition of more training examples does not improve the models performance on the training dataset.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5X4LvRZxyUZy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQWVOnY4cdA"
      },
      "source": [
        "# Plots the training and validation loss over the number of epochs.\n",
        "plt.plot(history_1.history['loss'])\n",
        "plt.plot(history_1.history['val_loss'])\n",
        "\n",
        "# Add plot title.\n",
        "plt.title('Model Loss')\n",
        "\n",
        "# Add plot axes labels.\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Add plot legend to distinguish between training and validation accuracy lines.\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "pp_oVWL6JPti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_1, test_acc_1 = model_1.evaluate(train_x, train_y)"
      ],
      "metadata": {
        "id": "uoz1XbfPJPWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "#**Part 2 - A network with only dense layers**\n"
      ],
      "metadata": {
        "id": "c4VQU_S6EdzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTGN_THiJaVx"
      },
      "source": [
        "## Model Definition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model has been designed to have a similar number of parameters to model_1. This was achieved by adjusting the number of units in each of the dense layers.\n",
        "\n",
        "> Model_1 has a total of 10369 parameters, and model_2 has 10371 parameters.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8KtKc80uIEXm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RH8MwGmJaVy"
      },
      "source": [
        "# Define the input layer of the model with the size of an image.\n",
        "input = layers.Input(shape=train_x[0].shape)\n",
        "\n",
        "# Flattens the outputs of the input layer into a 1D array.\n",
        "flatten = layers.Flatten()(input)\n",
        "\n",
        "# Dense layer 1 with 13 units and ReLU activation.\n",
        "dense_1 = layers.Dense(units=13, activation=\"relu\")(flatten)\n",
        "\n",
        "# Dense layer 2 with 11 units and ReLU activation.\n",
        "dense_2 = layers.Dense(units=11, activation=\"relu\")(dense_1)\n",
        "\n",
        "# Defines the output layer with a single node and sigmoid activation for binary classification.\n",
        "output = layers.Dense(units=1, activation=\"sigmoid\")(dense_2)\n",
        "\n",
        "# Initializes the defined model with the input and output layers.\n",
        "model_2 = Model(inputs=input, outputs=output, name=\"Model_2\")\n",
        "\n",
        "# Print the summary of the model.\n",
        "model_2.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_3TLHsvJaVy"
      },
      "source": [
        "## Model Training\n",
        "This is where we define the training options and then train the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBh5Q0-mJaVz"
      },
      "source": [
        "# Defines the parameters used during training.\n",
        "# Since the training regime is to be the same as for model_1, these parameters are the same as they were previously.\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhNxMt_lJaVz"
      },
      "source": [
        "# Define the optimizer with the above specified learning rate.\n",
        "optimizer = SGD(learning_rate=LEARNING_RATE)\n",
        "\n",
        "# Compile the model with the above defined optimizer, binary crossentropy loss, and accuracy metric.\n",
        "model_2.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLj3V4PpJaVz"
      },
      "source": [
        "# Train the model using training data generated in batches by the data generator.\n",
        "history_2 = model_2.fit(\n",
        "    data_generator.flow(train_x, train_y, batch_size=BATCH_SIZE),\n",
        "    # Calculate steps per epoch based on the number of training samples and batch size.\n",
        "    steps_per_epoch=len(train_x) / BATCH_SIZE,\n",
        "    # Use validation data generated in batches by the data generator.\n",
        "    validation_data=data_generator.flow(val_x, val_y, batch_size=BATCH_SIZE),\n",
        "    # Calculate validation steps based on the number of validation samples and batch size.\n",
        "    validation_steps=len(val_x) / BATCH_SIZE,\n",
        "    # Number of epochs to train the model.\n",
        "    epochs=NUM_EPOCHS\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqcJCxqmJaVz"
      },
      "source": [
        "## Plot Learning Curves\n",
        "This is where we visualise the training of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPkXhPbNJaV0"
      },
      "source": [
        "# Plots the training and validation accuracy over the number of epochs.\n",
        "plt.plot(history_2.history['accuracy'])\n",
        "plt.plot(history_2.history['val_accuracy'])\n",
        "\n",
        "# Add plot title.\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "# Add plot axes labels.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Add plot legend to distinguish between training and validation accuracy lines.\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTEzu65_JaV0"
      },
      "source": [
        "# Plots the training and validation loss over the number of epochs.\n",
        "plt.plot(history_2.history['loss'])\n",
        "plt.plot(history_2.history['val_loss'])\n",
        "\n",
        "# Add plot title.\n",
        "plt.title('Model Loss')\n",
        "\n",
        "# Add plot axes labels.\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Add plot legend to distinguish between training and validation accuracy lines.\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "o722eqcmJkPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_2, test_acc_2 = model_2.evaluate(train_x, train_y)"
      ],
      "metadata": {
        "id": "gU9-gnCAJkPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "#**Part 3 - A deep network of my own design**\n"
      ],
      "metadata": {
        "id": "RYoa9mzrOEHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "DzwZnPnnw05D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4pyD19twye9"
      },
      "source": [
        "# Defines the data generator for augmenting images during loading.\n",
        "data_generator = ImageDataGenerator(featurewise_center=True,  # Centers the pixel values of each image around zero.\n",
        "                                    featurewise_std_normalization=True,     # Standardizes the pixel values of each image.\n",
        "                                    horizontal_flip=True,     # Randomly flips images horizontally.\n",
        "                                    vertical_flip=True,     # Randomly flips images vertically.\n",
        "                                    rotation_range=10,     # Randomly rotates images within the specified range.\n",
        "                                    width_shift_range=0.1,     # Randomly shifts images horizontally within the specified range.\n",
        "                                    height_shift_range=0.1,     # Randomly shifts images vertically within the specified range.\n",
        "                                    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khemchtSwyfT"
      },
      "source": [
        "data_generator.fit(np.append(train_x, val_x, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1CpaZRwwqxC"
      },
      "source": [
        "## Model Definition\n",
        "In this section I will define the neural network arcitecture.\n",
        "\n",
        "The deep network model architecture consists of two convolutional and one dense layer, followed by an output layer for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer of the model with the size of an image.\n",
        "input = layers.Input(shape=train_x[0].shape)\n",
        "\n",
        "# Defines the convolutional layer with max pooling.\n",
        "conv_1 = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(input)\n",
        "pool_1 = layers.MaxPool2D(pool_size=(2, 2))(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(pool_1)\n",
        "\n",
        "# Flattens the outputs of the convolutional layers into a one-dimensional array.\n",
        "flatten = layers.Flatten()(conv_2)\n",
        "\n",
        "# Dense layer\n",
        "dense = layers.Dense(units=16, activation=\"relu\")(flatten)\n",
        "\n",
        "# Output layer:\n",
        "# Single node with sigmoid activation for binary classification.\n",
        "# L2 regularization with strength 0.01 is applied to kernel weights.\n",
        "output = layers.Dense(units=1, activation=\"sigmoid\", kernel_regularizer=regularizers.l2(0.01))(dense)\n",
        "\n",
        "# Initializes the defined model.\n",
        "model_3 = Model(inputs=input, outputs=output, name=\"Model_3\")\n",
        "# Print the model summary.\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "QbDTyZJpPtoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_LxQ_mtwqxO"
      },
      "source": [
        "## Model Training\n",
        "This is where we define the training options and then train the model.\n",
        "\n",
        "Through testing different values for the training parameters, I determined that a smaller batch size and more epochs was optimum.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNFhrInawqxO"
      },
      "source": [
        "# Defines the parameters used during training.\n",
        "BATCH_SIZE = 16 #Batch size should always be a power of 2 GPU allocation purposes (quicker as no additional calculations required by the computer)\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl6eQS4pwqxO"
      },
      "source": [
        "# Define the optimizer with the above specified learning rate.\n",
        "optimizer = SGD(learning_rate=LEARNING_RATE)\n",
        "\n",
        "# Compile the model with the above defined optimizer, binary crossentropy loss, and accuracy metric.\n",
        "model_3.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUTetjpAwqxO"
      },
      "source": [
        "# Train the model using training data generated in batches by the data generator.\n",
        "history_3 = model_3.fit(\n",
        "    data_generator.flow(train_x, train_y, batch_size=BATCH_SIZE),\n",
        "    # Calculate steps per epoch based on the number of training samples and batch size.\n",
        "    steps_per_epoch=len(train_x) / BATCH_SIZE,\n",
        "    # Use validation data generated in batches by the data generator.\n",
        "    validation_data=data_generator.flow(val_x, val_y, batch_size=BATCH_SIZE),\n",
        "    # Calculate validation steps based on the number of validation samples and batch size.\n",
        "    validation_steps=len(val_x) / BATCH_SIZE,\n",
        "    # Number of epochs to train the model.\n",
        "    epochs=NUM_EPOCHS\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BndlNJRwqxO"
      },
      "source": [
        "## Plot Learning Curves\n",
        "This is where we visualise the training of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Hqj5BpwqxP"
      },
      "source": [
        "# Plots the training and validation accuracy over the number of epochs.\n",
        "plt.plot(history_3.history['accuracy'])\n",
        "plt.plot(history_3.history['val_accuracy'])\n",
        "\n",
        "# Add plot title.\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "# Add plot axes labels.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Add plot legend to distinguish between training and validation accuracy lines.\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUjBwbCBwqxP"
      },
      "source": [
        "# Plots the training and validation loss over the number of epochs.\n",
        "plt.plot(history_3.history['loss'])\n",
        "plt.plot(history_3.history['val_loss'])\n",
        "\n",
        "# Add plot title.\n",
        "plt.title('Model Loss')\n",
        "\n",
        "# Add plot axes labels.\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Add plot legend to distinguish between training and validation accuracy lines.\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "9DU1gLaRJpyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_3, test_acc_3 = model_3.evaluate(train_x, train_y)"
      ],
      "metadata": {
        "id": "itXo2daTJpyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the models"
      ],
      "metadata": {
        "id": "9NAWNEhk8bMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the maximum validation accuracy for each model\n",
        "max_accs = [max(history_1.history['val_accuracy']), max(history_2.history['val_accuracy']), max(history_3.history['val_accuracy'])]\n",
        "\n",
        "# Retrieve the minimum validation loss for each model\n",
        "min_losses = [min(history_1.history['val_loss']), min(history_2.history['val_loss']), min(history_3.history['val_loss'])]\n",
        "\n",
        "# Table data\n",
        "data = [[\"Model 1\", max_accs[0], min_losses[0]],\n",
        "        [\"Model 2\", max_accs[1], min_losses[1]],\n",
        "        [\"Model 3\", max_accs[2], min_losses[2]]]\n",
        "\n",
        "# Display table\n",
        "print(tabulate(data, headers=[\"Model\", \"Max Vaidation Accuracy\", \"Min Validation Loss\"], tablefmt=\"fancy_grid\"))"
      ],
      "metadata": {
        "id": "6QYYPtiTF3hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising the accuracy and loss for all 3 models within the same plot:"
      ],
      "metadata": {
        "id": "Bijr8FxSJvP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create colour palette by getting three colors from the Inferno colormap\n",
        "colours = [cm.inferno(0.2), cm.inferno(0.5), cm.inferno(0.8)]"
      ],
      "metadata": {
        "id": "HLkWCvXYES-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot training and validation accuracy for the three models\n",
        "for i, history in enumerate([history_1, history_2, history_3]):\n",
        "    axs[0].plot(history.history['accuracy'], label=f'Model {i+1} Train', linestyle='dashed', color=colours[i])\n",
        "    axs[0].plot(history.history['val_accuracy'], label=f'Model {i+1} Validation', color=colours[i])\n",
        "\n",
        "# Add plot title and axis labels for the accuracy subplot\n",
        "axs[0].set_title('Training and Validation Accuracy for Three Models')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_xlim(-0.5, 9.5) # Set x-axis limit to show the first 10 epochs\n",
        "\n",
        "# Plot training and validation loss for the three models\n",
        "for i, history in enumerate([history_1, history_2, history_3]):\n",
        "    axs[1].plot(history.history['loss'], label=f'Model {i+1} Train', linestyle='dashed', color=colours[i])\n",
        "    axs[1].plot(history.history['val_loss'], label=f'Model {i+1} Validation', color=colours[i])\n",
        "\n",
        "# Add plot title and axis labels for the loss subplot\n",
        "axs[1].set_title('Training and Validation Loss for Three Models')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Loss')\n",
        "axs[1].set_xlim(-0.5, 9.5) # Set x-axis limit to show the first 10 epochs\n",
        "\n",
        "# Create a shared legend, below the subplots\n",
        "handles, labels = axs[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A0Kl2qX4PYio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}